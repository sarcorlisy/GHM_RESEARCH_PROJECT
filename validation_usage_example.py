"""
Validationä½¿ç”¨ç¤ºä¾‹ - å±•ç¤ºåœ¨demoä¸­çš„å…·ä½“è°ƒç”¨ä½ç½®
"""
import pandas as pd
import numpy as np
from data_loader import DataLoader
from data_preprocessor import DataPreprocessor
from feature_selector import FeatureSelector
from model_trainer import ModelTrainer
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def validation_usage_demo():
    """
    å±•ç¤ºvalidationåœ¨demoä¸­çš„å…·ä½“ä½¿ç”¨
    """
    logger.info("=" * 60)
    logger.info("VALIDATIONä½¿ç”¨ç¤ºä¾‹")
    logger.info("=" * 60)
    
    # ==================== ç¬¬ä¸€æ­¥ï¼šæ•°æ®åˆ†å‰² ====================
    logger.info("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šæ•°æ®åˆ†å‰² (Train/Validation/Test)")
    
    # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    loader = DataLoader()
    df = loader.merge_data()
    
    preprocessor = DataPreprocessor()
    df = preprocessor.apply_feature_engineering(df)
    df = preprocessor.prepare_target_variable(df)
    
    # ğŸ”‘ å…³é”®ï¼šä¸‰è·¯æ•°æ®åˆ†å‰²
    X_train, X_val, X_test, y_train, y_val, y_test = preprocessor.split_data(
        df, target_col='readmitted_binary', 
        test_size=0.2,  # 20% æµ‹è¯•é›†
        val_size=0.2,   # 20% éªŒè¯é›† (ä»å‰©ä½™80%ä¸­å–20%ï¼Œå³æ€»æ•°æ®çš„16%)
        random_state=42
    )
    
    logger.info(f"æ•°æ®åˆ†å‰²ç»“æœ:")
    logger.info(f"  è®­ç»ƒé›†: {X_train.shape} ({len(X_train)/len(df)*100:.1f}%)")
    logger.info(f"  éªŒè¯é›†: {X_val.shape} ({len(X_val)/len(df)*100:.1f}%)")
    logger.info(f"  æµ‹è¯•é›†: {X_test.shape} ({len(X_test)/len(df)*100:.1f}%)")
    
    # ç»§ç»­é¢„å¤„ç†
    X_train, X_val, X_test = preprocessor.encode_categorical_features(X_train, X_val, X_test)
    X_train, X_val, X_test = preprocessor.scale_numerical_features(X_train, X_val, X_test)
    X_train_balanced, y_train_balanced = preprocessor.apply_smote(X_train, y_train)
    
    # ==================== ç¬¬äºŒæ­¥ï¼šç‰¹å¾é€‰æ‹© ====================
    logger.info("\nğŸ” ç¬¬äºŒæ­¥ï¼šç‰¹å¾é€‰æ‹© (ä½¿ç”¨è®­ç»ƒé›†)")
    
    feature_selector = FeatureSelector()
    
    # åªåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œç‰¹å¾é€‰æ‹©
    selected_features = feature_selector.select_features_mutual_info(
        X_train_balanced, y_train_balanced, top_n=20
    )
    
    logger.info(f"é€‰æ‹©äº† {len(selected_features)} ä¸ªç‰¹å¾")
    
    # åº”ç”¨ç‰¹å¾é€‰æ‹©åˆ°æ‰€æœ‰æ•°æ®é›†
    X_train_selected = X_train_balanced[selected_features]
    X_val_selected = X_val[selected_features]      # ğŸ”‘ éªŒè¯é›†ä½¿ç”¨ç›¸åŒç‰¹å¾
    X_test_selected = X_test[selected_features]    # ğŸ”‘ æµ‹è¯•é›†ä½¿ç”¨ç›¸åŒç‰¹å¾
    
    # ==================== ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹è®­ç»ƒ ====================
    logger.info("\nğŸ¤– ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹è®­ç»ƒ (åœ¨è®­ç»ƒé›†ä¸Š)")
    
    model_trainer = ModelTrainer(random_state=42)
    
    # åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹
    training_results = model_trainer.train_all_models(
        X_train_selected, y_train_balanced, 
        X_val_selected, y_val  # ğŸ”‘ ä¼ å…¥éªŒè¯é›†ç”¨äºæ¦‚ç‡åˆ†å¸ƒå›¾
    )
    
    logger.info("è®­ç»ƒç»“æœ (Cross-Validation):")
    logger.info(training_results.to_string())
    
    # ==================== ç¬¬å››æ­¥ï¼šéªŒè¯é›†è¯„ä¼° ====================
    logger.info("\nâœ… ç¬¬å››æ­¥ï¼šéªŒè¯é›†è¯„ä¼° (æ¨¡å‹é€‰æ‹©)")
    
    # ğŸ”‘ å…³é”®ï¼šåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ‰€æœ‰æ¨¡å‹
    validation_results = model_trainer.evaluate_on_validation_set(X_val_selected, y_val)
    
    logger.info("éªŒè¯é›†ç»“æœ:")
    logger.info(validation_results.to_string())
    
    # ==================== ç¬¬äº”æ­¥ï¼šæ¨¡å‹é€‰æ‹© ====================
    logger.info("\nğŸ† ç¬¬äº”æ­¥ï¼šæ¨¡å‹é€‰æ‹© (åŸºäºéªŒè¯é›†æ€§èƒ½)")
    
    # åŸºäºéªŒè¯é›†AUCé€‰æ‹©æœ€ä½³æ¨¡å‹
    best_val_model_name = validation_results.loc[validation_results['auc'].idxmax(), 'model_name']
    best_val_auc = validation_results.loc[validation_results['auc'].idxmax(), 'auc']
    
    logger.info(f"éªŒè¯é›†æœ€ä½³æ¨¡å‹: {best_val_model_name} (AUC: {best_val_auc:.3f})")
    
    # åŸºäºéªŒè¯é›†F1é€‰æ‹©æœ€ä½³æ¨¡å‹
    best_val_f1_model_name = validation_results.loc[validation_results['f1'].idxmax(), 'model_name']
    best_val_f1 = validation_results.loc[validation_results['f1'].idxmax(), 'f1']
    
    logger.info(f"éªŒè¯é›†æœ€ä½³æ¨¡å‹ (F1): {best_val_f1_model_name} (F1: {best_val_f1:.3f})")
    
    # ==================== ç¬¬å…­æ­¥ï¼šæµ‹è¯•é›†è¯„ä¼° ====================
    logger.info("\nğŸ¯ ç¬¬å…­æ­¥ï¼šæµ‹è¯•é›†è¯„ä¼° (æœ€ç»ˆæ€§èƒ½)")
    
    # ğŸ”‘ å…³é”®ï¼šåªåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ç»ˆé€‰æ‹©çš„æ¨¡å‹
    test_results = model_trainer.evaluate_on_test_set(X_test_selected, y_test)
    
    logger.info("æµ‹è¯•é›†ç»“æœ:")
    logger.info(test_results.to_string())
    
    # ==================== ç¬¬ä¸ƒæ­¥ï¼šè¿‡æ‹Ÿåˆæ£€æµ‹ ====================
    logger.info("\nğŸ” ç¬¬ä¸ƒæ­¥ï¼šè¿‡æ‹Ÿåˆæ£€æµ‹")
    
    # æ¯”è¾ƒéªŒè¯é›†å’Œæµ‹è¯•é›†æ€§èƒ½
    for _, row in validation_results.iterrows():
        model_name = row['model_name']
        val_auc = row['auc']
        val_f1 = row['f1']
        
        # æ‰¾åˆ°å¯¹åº”çš„æµ‹è¯•é›†ç»“æœ
        test_row = test_results[test_results['model_name'] == model_name]
        if not test_row.empty:
            test_auc = test_row.iloc[0]['auc']
            test_f1 = test_row.iloc[0]['f1']
            
            val_test_auc_diff = abs(val_auc - test_auc)
            val_test_f1_diff = abs(val_f1 - test_f1)
            
            logger.info(f"\n{model_name}:")
            logger.info(f"  éªŒè¯é›†: AUC={val_auc:.3f}, F1={val_f1:.3f}")
            logger.info(f"  æµ‹è¯•é›†: AUC={test_auc:.3f}, F1={test_f1:.3f}")
            logger.info(f"  å·®å¼‚: AUCå·®å¼‚={val_test_auc_diff:.3f}, F1å·®å¼‚={val_test_f1_diff:.3f}")
            
            if val_test_auc_diff > 0.05:
                logger.warning(f"  âš ï¸  {model_name} å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ!")
            else:
                logger.info(f"  âœ… {model_name} æ³›åŒ–æ€§èƒ½è‰¯å¥½")
    
    # ==================== ç¬¬å…«æ­¥ï¼šè¶…å‚æ•°è°ƒä¼˜ç¤ºä¾‹ ====================
    logger.info("\nâš™ï¸ ç¬¬å…«æ­¥ï¼šè¶…å‚æ•°è°ƒä¼˜ç¤ºä¾‹")
    
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import roc_auc_score
    
    # ä¸ºRandomForestè°ƒä¼˜n_estimatorså‚æ•°
    n_estimators_list = [50, 100, 200, 300]
    val_scores = []
    
    logger.info("RandomForestè¶…å‚æ•°è°ƒä¼˜:")
    for n_estimators in n_estimators_list:
        model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)
        model.fit(X_train_selected, y_train_balanced)
        
        # ğŸ”‘ å…³é”®ï¼šåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        y_val_pred_proba = model.predict_proba(X_val_selected)[:, 1]
        val_auc = roc_auc_score(y_val, y_val_pred_proba)
        val_scores.append(val_auc)
        
        logger.info(f"  n_estimators={n_estimators}: éªŒè¯é›†AUC={val_auc:.3f}")
    
    best_n_estimators = n_estimators_list[np.argmax(val_scores)]
    logger.info(f"æœ€ä½³n_estimators: {best_n_estimators}")
    
    # ==================== æ€»ç»“ ====================
    logger.info("\n" + "=" * 60)
    logger.info("VALIDATIONä½¿ç”¨æ€»ç»“")
    logger.info("=" * 60)
    
    logger.info("""
    ğŸ“‹ Validationçš„æ­£ç¡®ä½¿ç”¨æµç¨‹:
    
    1. æ•°æ®åˆ†å‰²: Train(64%) + Validation(16%) + Test(20%)
    2. ç‰¹å¾é€‰æ‹©: åªåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œ
    3. æ¨¡å‹è®­ç»ƒ: åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒ
    4. éªŒè¯é›†è¯„ä¼°: è¯„ä¼°æ‰€æœ‰æ¨¡å‹ï¼Œé€‰æ‹©æœ€ä½³æ¨¡å‹
    5. è¶…å‚æ•°è°ƒä¼˜: åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ä¸åŒå‚æ•°
    6. æµ‹è¯•é›†è¯„ä¼°: åªåœ¨æœ€ç»ˆé€‰æ‹©çš„æ¨¡å‹ä¸Šè¿›è¡Œ
    7. è¿‡æ‹Ÿåˆæ£€æµ‹: æ¯”è¾ƒéªŒè¯é›†å’Œæµ‹è¯•é›†æ€§èƒ½
    
    âš ï¸ é‡è¦åŸåˆ™:
    - éªŒè¯é›†åªç”¨äºæ¨¡å‹é€‰æ‹©å’Œè¶…å‚æ•°è°ƒä¼˜
    - æµ‹è¯•é›†åªç”¨äºæœ€ç»ˆè¯„ä¼°ï¼Œä¸èƒ½ç”¨äºä»»ä½•è°ƒä¼˜
    - ç‰¹å¾é€‰æ‹©å¿…é¡»åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œ
    """)
    
    return {
        'training_results': training_results,
        'validation_results': validation_results,
        'test_results': test_results,
        'best_model': best_val_model_name
    }

if __name__ == "__main__":
    results = validation_usage_demo() 