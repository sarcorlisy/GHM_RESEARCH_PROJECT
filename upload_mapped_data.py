#!/usr/bin/env python3
"""
ä¸Šä¼ mappedæ•°æ®åˆ°Azure Data Lake
å°†ç»è¿‡mappingå¤„ç†çš„å®Œæ•´æ•°æ®ä¸Šä¼ åˆ°processed-dataå®¹å™¨
"""

import pandas as pd
import mysql.connector
from mysql.connector import Error
import logging
from datetime import datetime
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MappedDataUploader:
    def __init__(self, host='localhost', database='hospital_readmission', 
                 user='root', password='hospital123'):
        self.host = host
        self.database = database
        self.user = user
        self.password = password
        self.connection = None
        
    def connect(self):
        """è¿æ¥åˆ°MySQLæ•°æ®åº“"""
        try:
            self.connection = mysql.connector.connect(
                host=self.host,
                database=self.database,
                user=self.user,
                password=self.password
            )
            if self.connection.is_connected():
                logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {self.database}")
                return True
        except Error as e:
            logger.error(f"âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.connection and self.connection.is_connected():
            self.connection.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def get_mapped_data(self):
        """è·å–mappedæ•°æ®"""
        try:
            query = """
            SELECT 
                patient_id,
                encounter_id,
                race,
                gender,
                age,
                weight,
                admission_type_id,
                admission_type_desc,
                discharge_disposition_id,
                discharge_disposition_desc,
                admission_source_id,
                admission_source_desc,
                time_in_hospital,
                payer_code,
                medical_specialty,
                num_lab_procedures,
                num_procedures,
                num_medications,
                number_outpatient,
                number_emergency,
                number_inpatient,
                diag_1,
                diag_2,
                diag_3,
                number_diagnoses,
                max_glu_serum,
                A1Cresult,
                metformin,
                repaglinide,
                nateglinide,
                chlorpropamide,
                glimepiride,
                acetohexamide,
                glipizide,
                glyburide,
                tolbutamide,
                pioglitazone,
                rosiglitazone,
                acarbose,
                miglitol,
                troglitazone,
                tolazamide,
                examide,
                citoglipton,
                insulin,
                `glyburide-metformin`,
                `glipizide-metformin`,
                `glimepiride-pioglitazone`,
                `metformin-rosiglitazone`,
                `metformin-pioglitazone`,
                medication_change,
                diabetesMed,
                readmitted
            FROM patients_mapped
            WHERE patient_id IS NOT NULL
            """
            
            df = pd.read_sql(query, self.connection)
            logger.info(f"ğŸ“Š è·å–mappedæ•°æ®: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
            return df
            
        except Error as e:
            logger.error(f"âŒ è·å–mappedæ•°æ®å¤±è´¥: {e}")
            return None
    
    def save_to_csv(self, df, filename):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            df.to_csv(filename, index=False)
            logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
            return True
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜CSVå¤±è´¥: {e}")
            return False
    
    def upload_to_azure(self, local_file, container_name="processed-data", blob_name=None):
        """ä¸Šä¼ æ–‡ä»¶åˆ°Azure"""
        try:
            # å¯¼å…¥Azureç›¸å…³æ¨¡å—
            from azure.storage.blob import BlobServiceClient
            import os
            
            # è·å–è¿æ¥å­—ç¬¦ä¸²
            connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')
            
            if not connection_string:
                logger.error("âŒ æœªæ‰¾åˆ°AZURE_STORAGE_CONNECTION_STRINGç¯å¢ƒå˜é‡")
                return False
            
            # åˆ›å»ºblobå®¢æˆ·ç«¯
            blob_service_client = BlobServiceClient.from_connection_string(connection_string)
            container_client = blob_service_client.get_container_client(container_name)
            
            # ç”Ÿæˆblobåç§°
            if not blob_name:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                blob_name = f"mapped_data_{timestamp}.csv"
            
            # ä¸Šä¼ æ–‡ä»¶
            with open(local_file, "rb") as data:
                blob_client = container_client.get_blob_client(blob_name)
                blob_client.upload_blob(data, overwrite=True)
            
            logger.info(f"âœ… æˆåŠŸä¸Šä¼ åˆ°Azure: {container_name}/{blob_name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¼ Azureå¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Mappedæ•°æ®ä¸Šä¼ å·¥å…·")
    print("=" * 60)
    
    # åˆ›å»ºä¸Šä¼ å™¨
    uploader = MappedDataUploader()
    
    # è¿æ¥æ•°æ®åº“
    if not uploader.connect():
        return
    
    try:
        # è·å–mappedæ•°æ®
        df = uploader.get_mapped_data()
        if df is None:
            return
        
        # ä¿å­˜åˆ°æœ¬åœ°CSV
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        local_file = f"mapped_data_{timestamp}.csv"
        
        if uploader.save_to_csv(df, local_file):
            # ä¸Šä¼ åˆ°Azure
            if uploader.upload_to_azure(local_file, blob_name="mapped_data.csv"):
                print("ğŸ‰ Mappedæ•°æ®ä¸Šä¼ æˆåŠŸï¼")
                print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
                print(f"ğŸ“ æœ¬åœ°æ–‡ä»¶: {local_file}")
                print(f"â˜ï¸ Azureä½ç½®: processed-data/mapped_data.csv")
            else:
                print("âŒ Azureä¸Šä¼ å¤±è´¥")
        
        # æ¸…ç†æœ¬åœ°æ–‡ä»¶
        try:
            os.remove(local_file)
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†æœ¬åœ°æ–‡ä»¶: {local_file}")
        except:
            pass
            
    finally:
        uploader.disconnect()

if __name__ == "__main__":
    main() 